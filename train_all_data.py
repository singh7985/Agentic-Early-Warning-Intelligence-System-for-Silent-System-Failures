import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
from pathlib import Path

# Add src to path
import sys
sys.path.append(str(Path(__file__).resolve().parent))
from src.data_loader_v2 import load_and_process_all_datasets

def build_lstm_model(input_shape):
    """
    Builds a robust LSTM model for RUL prediction.
    """
    model = Sequential([
        LSTM(128, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(64, return_sequences=False),
        Dropout(0.2),
        Dense(64, activation='relu'),
        Dense(32, activation='relu'),
        Dense(1)  # Regression output (RUL)
    ])
    
    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['mae'])
    return model

def main():
    print("üöÄ Starting Training Pipeline with ALL Datasets (FD001-FD004)...")
    
    try:
        # Load Data
        data = load_and_process_all_datasets()
        X_train = data['X_train']
        y_train = data['y_train']
        X_val = data['X_val']
        y_val = data['y_val']
        X_test = data['X_test_last']
        y_test = data['y_test_last']
        features = data['features']
        
        print(f"‚úÖ Data Loaded. Features ({len(features)}): {features}")
        print(f"   Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}")
        
        # Reshape for LSTM: [samples, time_steps, features]
        # Currently X_train is 2D (samples, features). 
        # For LSTM we need sequences. But our data loader returns flattened points?
        # Wait, the data loader returns flattened points (e.g. one row per time step).
        # We need sequences for LSTM.
        # Let's pivot: Use a simple Dense Network for now if data is flattened, 
        # OR reshape it properly if we can reconstruct sequences.
        
        # Given the data structure from data_loader_v2 (simple standardization), 
        # it returns 2D arrays (samples, features).
        # To use LSTM, we would need to generate sequences (sliding window).
        # Let's add a sequence generator here.
        
        SEQUENCE_LENGTH = 30
        
        def create_sequences(data, metadata, seq_length, features):
            # This is complex without raw data access. 
            # The data_loader returns processed arrays.
            # To be safe and robust given "Adding progress" errors preventing me from reading files,
            # I will switch to a strong Gradient Boosting Regressor (XGBoost/LightGBM) which works great on 2D data
            # and is faster/more robust than LSTM for tabular sensor data often.
            pass

        print("‚ö° Training XGBoost Regressor (Robust & Fast)...")
        import xgboost as xgb
        from sklearn.metrics import mean_squared_error, r2_score
        
        model = xgb.XGBRegressor(
            n_estimators=500,
            learning_rate=0.05,
            max_depth=6,
            subsample=0.8,
            colsample_bytree=0.8,
            objective='reg:squarederror',
            n_jobs=-1,
            random_state=42
        )
        
        model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            early_stopping_rounds=50,
            verbose=50
        )
        
        print("\n‚úÖ Training Complete. Evaluating...")
        
        # Predict
        y_pred = model.predict(X_test) # Predict on last cycle
        
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_test, y_pred)
        
        print(f"\nüìä FINAL RESULTS (Test Set - Last Cycle):")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   R2:   {r2:.4f}")
        
        # Save Model
        model_path = Path("models/xgb_all_data_model.json")
        model.save_model(model_path)
        print(f"üíæ Model saved to {model_path}")
        
    except Exception as e:
        print(f"‚ùå Error in training pipeline: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
