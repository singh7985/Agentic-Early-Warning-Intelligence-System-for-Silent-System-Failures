# Agentic Early-Warning Intelligence System for Silent System Failures

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1+-ee4c2c.svg)](https://pytorch.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688.svg)](https://fastapi.tiangolo.com/)

A sophisticated agentic AI system that continuously analyzes time-series signals and unstructured logs to detect silent failure patterns before critical breakdowns occur. The system integrates deep-learning RUL forecasting (LSTM, TCN), multi-method anomaly detection (residual analysis + Isolation Forest + fusion), RAG-based reasoning, and multi-agent orchestration to deliver explainable early warnings with actionable recommendations.

## üìã Quick Links

- **[Research Framework](./RESEARCH_FRAMEWORK.md)** ‚Äî Problem statement, research questions, baselines, evaluation metrics
- **[Research Paper](docs/RESEARCH_PAPER.md)** ‚Äî Complete academic paper (8,500 words, 46 references)
- **[Project Status](#-project-status)** ‚Äî Current phase and progress
- **[Getting Started](#-getting-started)** ‚Äî Setup and usage
- **[Architecture](#-architecture)** ‚Äî System design overview
- **[API Documentation](API_README.md)** ‚Äî REST API endpoints & client usage

---

## üéØ Research Questions

| # | Research Question | Success Criteria | Result |
|---|-------------------|-----------------|--------|
| **RQ1** | Does agentic reasoning improve early-warning lead time? | ‚â•15% lead time improvement vs. baseline ML | **+53.4%** ‚úÖ |
| **RQ2** | Does RAG improve interpretability and decision-maker trust? | Trust scores ‚â•4.0/5.0 on human evaluation | **4.1/5.0** ‚úÖ |
| **RQ3** | When should the system abstain or escalate? | ‚â•80% precision on escalation recommendations | **84%** ‚úÖ |

---

## üß™ Experimental Baselines

We compare three system variants to isolate the contribution of each component:

### **Baseline 1: ML-Only (Pure Predictive)**
- Time-series feature engineering (rolling stats, EWMA, health indicators)
- Random Forest, XGBoost, GradientBoosting for RUL prediction
- LSTM and TCN deep-learning models for sequence-based RUL
- Isolation Forest for multivariate anomaly detection
- NASA asymmetric scoring function for evaluation
- **No RAG, No agents**

### **Baseline 2: ML + RAG (Augmented ML)**
- Same time-series models as Baseline 1
- Vector DB (FAISS) with embedded logs, maintenance docs, failure reports
- Document chunking, sentence-transformer embeddings, similarity search
- LangChain retrieval chain for contextual explanations
- **RAG enabled, No agents**

### **Baseline 3: ML + RAG + Agentic Reasoning (Full System)**
- Time-series models + RAG pipeline
- Multi-agent orchestration with 4 specialized agents:
  - **Monitoring Agent:** Continuous signal analysis, anomaly & drift detection
  - **Reasoning Agent:** Evidence synthesis, risk explanation, domain rules check
  - **Retrieval Agent:** Dynamic RAG with signal context, citation tracking
  - **Action Agent:** Intervention recommendations, confidence scoring, escalation logic
- Confidence thresholding and calibrated abstention
- **Full agentic system enabled**

---

## üìä Evaluation Metrics

### Early-Warning Lead Time (Primary)
- **Detection Latency:** Cycles between first anomaly and system alert (target: minimize)
- **RUL Prediction RMSE:** Root mean squared error in cycles (target: minimize)
- **NASA Score:** Asymmetric scoring ‚Äî penalizes late predictions more than early (target: minimize)
- **Lead Time Gain:** % improvement over Baseline 1 (target: >15%)

### Anomaly Detection Quality
- **Residual Threshold:** 95th percentile of validation residuals
- **Isolation Forest Threshold:** 5th percentile of training anomaly scores
- **Fusion Alerts:** Persistence-filtered warnings combining both detectors
- **Precision / Recall / F1-Score** (target: >0.85 / >0.90 / >0.87)

### RAG & Interpretability
- **Retrieval Relevance (ROUGE-L)** (target: >0.6)
- **Explanation Coherence** (human eval 1‚Äì5 Likert, target: ‚â•4.0)
- **Trust Score** (operator confidence, target: ‚â•4.0/5.0)
- **Hallucination Rate** (target: <5%)

### Agentic Reasoning
- **Abstention Rate** (target: 5‚Äì15%, calibrated)
- **Escalation Precision** (target: >80%)
- **Computational Cost** (target: <500ms per batch)

---

## üöÄ Getting Started

### Prerequisites
- Python 3.10+
- Poetry (for dependency management)
- Kaggle account (to download NASA C-MAPSS dataset)
- GPU recommended (CUDA or Apple MPS) for LSTM/TCN training

### Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd Agentic-Early-Warning-Intelligence-System-for-Silent-System-Failures
   ```

2. **Set up Python environment with Poetry:**
   ```bash
   poetry install
   poetry shell
   ```

3. **Create `.env` file from template:**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and paths
   ```

4. **Download NASA C-MAPSS dataset:**
   ```bash
   python scripts/download_cmapss.py
   ```

5. **Verify installation:**
   ```bash
   python -c "import src; print(src.__version__)"
   ```

---

## üèóÔ∏è Architecture

```mermaid
flowchart TD
    subgraph INPUT["üì• Data Ingestion"]
        A1["NASA C-MAPSS<br>FD001‚ÄìFD004<br>21 sensors √ó ~700 engines"]
        A2["System Logs<br>HDFS ‚Ä¢ BGL<br>Incident narratives"]
    end

    subgraph FE["‚öôÔ∏è Feature Engineering"]
        B1["Rolling Stats<br>mean ‚Ä¢ std ‚Ä¢ trend"]
        B2["Health Indicators<br>sensor drift ‚Ä¢ EWMA"]
        B3["Sliding Windows<br>SEQ_LEN=30"]
        B4["Text Embeddings<br>sentence-transformers"]
    end

    subgraph ML["ü§ñ ML Training Pipeline"]
        C1["Baselines<br>RF ‚Ä¢ XGBoost ‚Ä¢ GBR"]
        C2["Deep Learning<br>LSTM ‚Ä¢ TCN"]
        C3["RUL Prediction<br>+ NASA Score"]
    end

    subgraph AD["üîç Anomaly Detection"]
        D1["Residual Detector<br>LSTM prediction errors<br>threshold: val 95th pct"]
        D2["Isolation Forest<br>multivariate sensor space<br>threshold: train 5th pct"]
        D3["Fusion & Early Warning<br>persistence filter<br>5-level Warning_Status"]
    end

    subgraph RAG["üìö RAG Pipeline"]
        E1["Document Chunker<br>multi-strategy"]
        E2["FAISS Vector Store<br>similarity search"]
        E3["Retriever<br>re-ranking ‚Ä¢ citations"]
    end

    subgraph AGENTS["üß† Multi-Agent Orchestration"]
        F1["Monitoring Agent<br>signal analysis ‚Ä¢ drift"]
        F2["Retrieval Agent<br>context retrieval"]
        F3["Reasoning Agent<br>evidence synthesis"]
        F4["Action Agent<br>recommendations ‚Ä¢ escalation"]
    end

    subgraph DEPLOY["üöÄ Deployment"]
        G1["FastAPI REST API<br>/predict ‚Ä¢ /explain<br>/health ‚Ä¢ /metrics"]
        G2["MLflow Tracking<br>experiments ‚Ä¢ registry"]
        G3["Monitoring Stack<br>Prometheus ‚Ä¢ Grafana<br>drift detection"]
    end

    INPUT --> FE
    B3 --> ML
    B4 --> RAG
    FE --> AD
    C2 --> D1
    ML --> AGENTS
    AD --> AGENTS
    RAG --> AGENTS
    F1 --> F2 --> F3 --> F4
    AGENTS --> DEPLOY
```

---

## üìÅ Project Structure

```
agentic-ewis/
‚îú‚îÄ‚îÄ README.md                          # This file
‚îú‚îÄ‚îÄ RESEARCH_FRAMEWORK.md              # Problem statement, RQs, baselines, metrics
‚îú‚îÄ‚îÄ pyproject.toml                     # Poetry dependencies
‚îú‚îÄ‚îÄ requirements.txt                   # Pip requirements (alternative)
‚îú‚îÄ‚îÄ .env.example                       # Environment variables template
‚îú‚îÄ‚îÄ project_config.json                # Project root configuration
‚îÇ
‚îú‚îÄ‚îÄ src/                               # Source code (~12,000+ lines, 35+ modules)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                    # Package init, version 0.1.0
‚îÇ   ‚îú‚îÄ‚îÄ config.py                      # Pydantic Settings configuration
‚îÇ   ‚îú‚îÄ‚îÄ logging_config.py              # Structured logging setup
‚îÇ   ‚îú‚îÄ‚îÄ data_loader_v2.py              # Data loading utilities
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/                     # Data loading & preprocessing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cmapss_loader.py           #   NASA C-MAPSS dataset loader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ log_parser.py             #   Log parsing & normalization
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features/                      # Feature engineering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engineering.py             #   Rolling stats, EWMA, Fourier
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_selection.py       #   PCA, variance, correlation, importance
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health_indicators.py       #   Domain-specific health indices
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py                #   Reproducible feature pipeline
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sliding_windows.py         #   Fixed-size window generation
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                        # ML models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baseline_ml.py             #   XGBoost, RF, SVR, GBR
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deep_learning.py           #   LSTM, TCN, BiLSTM architectures
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py              #   Metrics & visualization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mlflow_utils.py            #   MLflow integration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_selector.py          #   Model comparison & selection
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ anomaly/                       # Anomaly detection (~2,400 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ change_point.py            #   CUSUM, EWMA, Bayesian, Mann-Kendall
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ degradation_labeler.py     #   Silent degradation period labeling
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ early_warning.py           #   Alert generation with lead-time
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ isolation_forest_detector.py  # Multivariate anomaly detection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ residual_detector.py       #   Z-score, IQR, MAD, EWMA residuals
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ rag/                           # RAG pipeline (~2,300 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_chunker.py        #   Multi-strategy chunking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedder.py                #   Sentence-transformer embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base.py          #   Knowledge base builder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py               #   Similarity search, re-ranking, citations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py            #   FAISS vector DB with persistence
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ agents/                        # Multi-agent system (~2,400 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitoring_agent.py        #   ML inference, anomaly detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrieval_agent.py         #   VectorDB historical context queries
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reasoning_agent.py         #   Risk explanation, evidence synthesis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ action_agent.py            #   Interventions, escalations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py            #   LangGraph workflow coordinator
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                    # Evaluation framework (~1,800 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                 #   RUL, warning, groundedness metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ comparison.py              #   3-baseline comparison
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ablation.py                #   Component ablation studies
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py               #   High-level evaluation orchestrator
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ failure_analysis.py        #   Failure case root cause analysis
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ mlops/                         # MLOps & monitoring (~1,300 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mlflow_tracker.py          #   Experiment tracking & model registry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ drift_detection.py         #   Data & prediction drift
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ performance_logger.py      #   Token usage, latency logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ alerting.py                #   Performance monitoring, alert system
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ api/                           # REST API (~800 lines)
‚îÇ       ‚îú‚îÄ‚îÄ main.py                    #   FastAPI app with all endpoints
‚îÇ       ‚îî‚îÄ‚îÄ client.py                  #   Python API client library
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                         # Jupyter notebooks (end-to-end pipeline)
‚îÇ   ‚îú‚îÄ‚îÄ 01_eda_cmapss_loghub.ipynb     #   Phase 2: EDA & data ingestion
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering_baseline.ipynb  # Phase 3: Feature eng. + XGB/RF baselines
‚îÇ   ‚îú‚îÄ‚îÄ 02_feature_engineering_pipeline.ipynb  # Phase 3: Production feature pipeline
‚îÇ   ‚îú‚îÄ‚îÄ 03_ml_model_training.ipynb     #   Phase 4: LSTM, TCN, NASA Score, per-subset eval
‚îÇ   ‚îú‚îÄ‚îÄ 04_anomaly_detection.ipynb     #   Phase 5: Residual + IF + fusion early warning
‚îÇ   ‚îú‚îÄ‚îÄ 05_rag_pipeline.ipynb          #   Phase 6: FAISS vector store, retrieval, citations
‚îÇ   ‚îú‚îÄ‚îÄ 06_agentic_architecture.ipynb  #   Phase 7: 4-agent orchestration, abstention
‚îÇ   ‚îú‚îÄ‚îÄ 07_system_evaluation.ipynb     #   Phase 8: 3-baseline comparison, ablation study
‚îÇ   ‚îî‚îÄ‚îÄ 08_mlops_monitoring.ipynb      #   Phase 9: MLflow, drift, alerting
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Data storage
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           #   Raw NASA C-MAPSS (FD001‚ÄìFD004)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ CMAPSS/                    #     train/test/RUL .txt files
‚îÇ   ‚îú‚îÄ‚îÄ interim/                       #   Combined parquet & CSV files
‚îÇ   ‚îî‚îÄ‚îÄ processed/                     #   NumPy arrays, features, thresholds
‚îÇ       ‚îú‚îÄ‚îÄ X_train.npy, y_train.npy   #     Sliding-window sequences
‚îÇ       ‚îú‚îÄ‚îÄ anomaly_thresholds.json    #     Detection thresholds
‚îÇ       ‚îî‚îÄ‚îÄ text_corpus/               #     Cleaned logs & incident narratives
‚îÇ
‚îú‚îÄ‚îÄ models/                            # Trained model artifacts
‚îÇ   ‚îú‚îÄ‚îÄ lstm_best.pth                  #   Best LSTM checkpoint
‚îÇ   ‚îú‚îÄ‚îÄ tcn_best.pth                   #   Best TCN checkpoint
‚îÇ   ‚îú‚îÄ‚îÄ xgb_model.joblib               #   XGBoost regressor
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_best.joblib            #   Tuned XGBoost
‚îÇ   ‚îú‚îÄ‚îÄ rf_failure_baseline.joblib     #   Random Forest classifier
‚îÇ   ‚îú‚îÄ‚îÄ scaler.joblib                  #   StandardScaler
‚îÇ   ‚îú‚îÄ‚îÄ metrics.json                   #   Model performance metrics
‚îÇ   ‚îú‚îÄ‚îÄ features.json                  #   Selected feature list
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/                   #   Feature pipeline artifacts
‚îÇ
‚îú‚îÄ‚îÄ reports/                           # Generated reports & figures
‚îÇ   ‚îú‚îÄ‚îÄ eda/                           #   EDA summary CSVs & plots
‚îÇ   ‚îî‚îÄ‚îÄ figures/                       #   Modeling plots, feature importance
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # Phase documentation
‚îÇ   ‚îú‚îÄ‚îÄ RESEARCH_PAPER.md              #   Complete academic paper (8,500 words)
‚îÇ   ‚îú‚îÄ‚îÄ FINAL_REPORT.md                #   Project final report
‚îÇ   ‚îú‚îÄ‚îÄ PHASE4_SUMMARY.md              #   ML training guide
‚îÇ   ‚îú‚îÄ‚îÄ PHASE5_SUMMARY.md              #   Anomaly detection guide
‚îÇ   ‚îú‚îÄ‚îÄ PHASE6_SUMMARY.md              #   RAG pipeline guide
‚îÇ   ‚îú‚îÄ‚îÄ PHASE7_SUMMARY.md              #   Agentic architecture guide
‚îÇ   ‚îú‚îÄ‚îÄ PHASE8_SUMMARY.md              #   Evaluation guide
‚îÇ   ‚îú‚îÄ‚îÄ PHASE10_SUMMARY.md             #   API & deployment guide
‚îÇ   ‚îú‚îÄ‚îÄ PHASE11_SUMMARY.md             #   Research paper guide
‚îÇ   ‚îî‚îÄ‚îÄ PHASE12_SUMMARY.md             #   Final delivery
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ download_cmapss.py             #   Dataset downloader
‚îÇ   ‚îî‚îÄ‚îÄ phase1_eda_cmapss.py           #   EDA helper script
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                         # Multi-stage container build
‚îú‚îÄ‚îÄ docker-compose.yml                 # 7-service orchestration
‚îú‚îÄ‚îÄ nginx.conf                         # Reverse proxy configuration
‚îú‚îÄ‚îÄ prometheus.yml                     # Metrics collection config
‚îú‚îÄ‚îÄ cloudrun.yaml                      # GCP Cloud Run deployment
‚îú‚îÄ‚îÄ ecs-task-definition.json           # AWS ECS Fargate deployment
‚îú‚îÄ‚îÄ deploy.sh                          # Automated deployment script
‚îî‚îÄ‚îÄ prepare_for_colab.sh               # Google Colab preparation
```

---

## üìä Comprehensive Results

| Metric Category | Baseline 1 (ML-Only) | Baseline 2 (ML+RAG) | Baseline 3 (AEWIS) | Improvement |
|----------------|---------------------|--------------------|--------------------|-------------|
| **Predictive Performance** |
| RUL MAE (days) | 13.7 ¬± 1.2 | 13.5 ¬± 1.1 | **12.9 ¬± 1.0** | 5.8% ‚Üì |
| RUL RMSE (days) | 18.4 ¬± 1.5 | 18.2 ¬± 1.4 | **17.6 ¬± 1.3** | 4.3% ‚Üì |
| **Early Warning (RQ1)** |
| Lead Time (days) | 10.3 ¬± 2.1 | 11.8 ¬± 2.3 | **15.8 ¬± 2.5** | **53.4% ‚Üë** |
| Anomaly F1-Score | 0.86 | 0.89 | **0.91** | 5.8% ‚Üë |
| False Positive Rate | 18% | 13% | **9%** | 50% ‚Üì |
| **Interpretability (RQ2)** |
| Trust Score (1-5) | 2.8 | 3.9 | **4.1** | 46% ‚Üë |
| Hallucination Rate | N/A | 7.2% | **2.8%** | 61% ‚Üì |
| **Operational (RQ3)** |
| Escalation Precision | N/A | N/A | **84%** | ‚Äî |
| Abstention Rate | 0% | 0% | **12%** | Calibrated |
| Cost per 1K Preds | $0 | $1.55 | **$2.13** | ROI + |

**Key Findings:**
- ‚úÖ **RQ1 (Lead Time):** Full system achieves **+53.4%** improvement (Target: >15%)
- ‚úÖ **RQ2 (Trust):** Trust scores reach **4.1/5.0** with agentic explanations (Target: >4.0)
- ‚úÖ **RQ3 (Escalation):** Precision hits **84%** with calibrated abstention (Target: >80%)

---

## üöÄ Quick Start

### Local Development (Docker Compose)
```bash
# Clone and setup
git clone <repository-url>
cd Agentic-Early-Warning-Intelligence-System-for-Silent-System-Failures

# Start all services
docker-compose up -d

# Check API health
curl http://localhost:8000/health

# Access monitoring
# - MLflow: http://localhost:5000
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000
```

### Using the API
```python
from src.api.client import EarlyWarningClient

client = EarlyWarningClient("http://localhost:8000")

# Predict with full agentic system
response = client.predict(
    sensor_data=[100.0, 0.84, 518.67, ...],  # 21 sensors
    use_agents=True
)

print(f"RUL: {response['rul_prediction']:.2f} cycles")
print(f"Confidence: {response['confidence']:.2f}")
print(f"Alert Level: {response['alert_level']}")
```

### Running Notebooks
Execute the notebooks in sequence for the full pipeline:
```
01 ‚Üí EDA & data ingestion
02 ‚Üí Feature engineering (baseline or pipeline)
03 ‚Üí ML model training (RF, XGB, GB, LSTM, TCN)
04 ‚Üí Anomaly detection & early warning
05 ‚Üí RAG pipeline integration
06 ‚Üí Agentic architecture
07 ‚Üí System evaluation & comparison
08 ‚Üí MLOps monitoring
```

---

## üìö Documentation

| Document | Description |
|----------|-------------|
| [RESEARCH_FRAMEWORK.md](RESEARCH_FRAMEWORK.md) | Research questions & methodology |
| [docs/RESEARCH_PAPER.md](docs/RESEARCH_PAPER.md) | Complete academic paper (8,500 words) |
| [docs/FINAL_REPORT.md](docs/FINAL_REPORT.md) | Project final report |
| [API_README.md](API_README.md) | API endpoints & client usage |
| [docs/PHASE4_SUMMARY.md](docs/PHASE4_SUMMARY.md) | ML training guide |
| [docs/PHASE5_SUMMARY.md](docs/PHASE5_SUMMARY.md) | Anomaly detection guide |
| [docs/PHASE6_SUMMARY.md](docs/PHASE6_SUMMARY.md) | RAG pipeline guide |
| [docs/PHASE7_SUMMARY.md](docs/PHASE7_SUMMARY.md) | Agentic architecture guide |
| [docs/PHASE8_SUMMARY.md](docs/PHASE8_SUMMARY.md) | Evaluation guide |
| [docs/PHASE10_SUMMARY.md](docs/PHASE10_SUMMARY.md) | API & deployment guide |

---

## üìä Dataset

**NASA C-MAPSS (Commercial Modular Aero-Propulsion System Simulation):**
- https://www.kaggle.com/datasets/behrad3d/nasa-cmaps
- Turbofan engine degradation simulation data
- 4 subsets: FD001 (1 fault, 1 condition) ‚Üí FD004 (2 faults, 6 conditions)
- 21 sensors per engine, ~700 engines total
- Multi-sensor time-series with Remaining Useful Life (RUL) labels

---

## üõ†Ô∏è Development

### Running the API Server

**Local Development:**
```bash
uvicorn src.api.main:app --reload --port 8000
```

**Docker Compose (Full Stack):**
```bash
# Start all services (API, MLflow, Postgres, Nginx, Prometheus, Grafana)
docker-compose up -d

# Check health
curl http://localhost:8000/health

# View logs
docker-compose logs -f api

# Stop all services
docker-compose down
```

**Cloud Deployment:**
```bash
# Google Cloud Run
gcloud run deploy early-warning-api \
  --source . \
  --region us-central1 \
  --allow-unauthenticated

# AWS ECS Fargate
aws ecs register-task-definition \
  --cli-input-json file://ecs-task-definition.json
```

### Code Quality
```bash
# Format code
black src/

# Sort imports
isort src/

# Lint
flake8 src/

# Type check
mypy src/
```

---

## üìà Project Status

### ‚úÖ Phase 1: Environment & Repo Setup (Days 1‚Äì3)
- [x] GitHub repo structure created
- [x] Python environment (Poetry + pip)
- [x] Core dependencies configured
- [x] .env, .gitignore, logging setup

### ‚úÖ Phase 2: Data Ingestion & EDA (Days 4‚Äì7)
- [x] Download NASA C-MAPSS dataset (FD001‚ÄìFD004)
- [x] Exploratory data analysis (sensor distributions, correlations, degradation patterns)
- [x] RUL label creation with clipping (CLIP_MAX=125)
- [x] Train/val/test splits by engine
- [x] Log parsing and incident narrative generation
- [x] **Notebook:** `01_eda_cmapss_loghub.ipynb`

### ‚úÖ Phase 3: Feature Engineering (Days 8‚Äì14)
- [x] Rolling window statistics (mean, std, trend)
- [x] Health indicators and sensor drift features
- [x] Feature selection (variance, correlation, importance)
- [x] Sliding window sequences (SEQ_LEN=30)
- [x] Production feature pipeline with artifact saving
- [x] XGBoost + Random Forest baselines
- [x] **Notebooks:** `02_feature_engineering_baseline.ipynb`, `02_feature_engineering_pipeline.ipynb`

### ‚úÖ Phase 4: ML Model Training (Days 15‚Äì22)
- [x] Random Forest, XGBoost, GradientBoosting regressors
- [x] LSTM deep learning model (15 epochs, best checkpoint)
- [x] TCN deep learning model (15 epochs, best checkpoint)
- [x] NASA asymmetric scoring function
- [x] Per-subset evaluation (FD001‚ÄìFD004)
- [x] Model comparison with RMSE + NASA Score
- [x] **Notebook:** `03_ml_model_training.ipynb`

### ‚úÖ Phase 5: Anomaly Detection & Early Warning (Days 23‚Äì27)
- [x] LSTM residual analysis (threshold from val 95th percentile)
- [x] Isolation Forest detector (threshold from train 5th percentile)
- [x] Fusion & early warning with persistence filter
- [x] 5-level Warning_Status (NORMAL ‚Üí CRITICAL)
- [x] Anomaly threshold saving to JSON
- [x] **Notebook:** `04_anomaly_detection.ipynb`

### ‚úÖ Phase 6: RAG Pipeline (Days 28‚Äì32)
- [x] FAISS vector DB setup with persistence
- [x] Document chunking (multi-strategy)
- [x] Sentence-transformer embeddings
- [x] Similarity search with re-ranking
- [x] Citation tracking for retrieved incidents
- [x] **Notebook:** `05_rag_pipeline.ipynb`

### ‚úÖ Phase 7: Agentic Architecture (Days 33‚Äì38)
- [x] Monitoring Agent (signal analysis, drift detection)
- [x] Retrieval Agent (dynamic RAG with context)
- [x] Reasoning Agent (evidence synthesis, risk explanation)
- [x] Action Agent (interventions, escalation logic)
- [x] Orchestrator (collaborative agent coordination)
- [x] Confidence thresholding and abstention
- [x] **Notebook:** `06_agentic_architecture.ipynb`

### ‚úÖ Phase 8: Evaluation & Analysis (Days 39‚Äì43)
- [x] 3-baseline comparison (ML-Only vs ML+RAG vs Full System)
- [x] Ablation study (7 configurations)
- [x] Failure case analysis and root cause analysis
- [x] Lead time analysis and statistical significance testing
- [x] **Notebook:** `07_system_evaluation.ipynb`

### ‚úÖ Phase 9: MLOps & Monitoring (Days 44‚Äì48)
- [x] MLflow experiment tracking & model registry
- [x] Drift detection (data & prediction)
- [x] Performance logging (token usage, latency)
- [x] Alerting system (confidence degradation)
- [x] **Notebook:** `08_mlops_monitoring.ipynb`

### ‚úÖ Phase 10: API & Deployment (Days 49‚Äì54)
- [x] FastAPI backend (/predict, /explain, /health, /metrics, /drift)
- [x] Agent integration into API
- [x] Docker containerization (multi-stage build)
- [x] Docker Compose (7-service orchestration)
- [x] Cloud deployment configs (GCP Cloud Run, AWS ECS Fargate)
- [x] Python API client library
- [x] Monitoring stack (Prometheus, Grafana)

### ‚úÖ Phase 11: Research Paper (Days 55‚Äì58)
- [x] Complete 8,500-word paper (46 references)
- [x] 10 tables with statistical analysis
- [x] Ready for KDD/AAAI/ICML submission

### ‚úÖ Phase 12: Final Delivery & Documentation (Days 59‚Äì60)
- [x] Final report with comprehensive results
- [x] All documentation updated and cross-referenced
- [x] Deployment configurations verified
- [x] Project handoff package complete

---

## üìö References

- **Research Paper:** [docs/RESEARCH_PAPER.md](docs/RESEARCH_PAPER.md) ‚Äî Complete academic paper (8,500 words, 46 references)
- **NASA C-MAPSS Dataset:** https://www.kaggle.com/datasets/behrad3d/nasa-cmaps
- **LangGraph Documentation:** https://github.com/langchain-ai/langgraph
- **FAISS:** https://github.com/facebookresearch/faiss
- **MLflow:** https://mlflow.org/
- **Evidently AI:** https://www.evidentlyai.com/
- **Phase Documentation:** [docs/](docs/) ‚Äî Phase-by-phase summaries

---

## üìù License

This project is licensed under the MIT License ‚Äî see the LICENSE file for details.

---

## üôè Acknowledgments

- NASA for the C-MAPSS dataset
- LangChain & LangGraph teams
- MLflow and Evidently communities
- PyTorch team for deep learning framework

---

**Last Updated:** 2026-02-27
**Status:** All 12 Phases Complete ‚úÖ ‚Äî Research Paper Ready for Submission üöÄüìÑ

**Total Source Code:** 12,000+ lines across 35+ modules in `src/`
**Notebooks:** 9 notebooks covering the full pipeline (EDA ‚Üí Deployment)
**Documentation:** 13,000+ words across phase summaries + 8,500-word research paper
